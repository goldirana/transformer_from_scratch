{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\n",
      "\u001b[1m3423204/3423204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "/Users/goldyrana/.keras/datasets/fra.txt\n"
     ]
    }
   ],
   "source": [
    "# download dataset provided by Anki: https://www.manythings.org/anki/\n",
    "text_file = tf.keras.utils.get_file(\n",
    "    fname=\"fra-eng.zip\",\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "# show where the file is located now\n",
    "text_file = pathlib.Path(text_file).parent / \"fra.txt\"\n",
    "print(text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 2: Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French letters have accents which would be represented as Unicode characters, but such representation is not unique in Unicode. Therefore, you will convert the string into NFKC (compatibility and composition normal form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('just looking at her , you can tell that she likes you .', \"[start] juste en la regardant , vous pouvez voir qu'elle vous aime . [end]\")\n",
      "('that made me cry .', \"[start] ça m'a fait pleurer . [end]\")\n",
      "('i want to cut down on the time it takes to process records .', '[start] je veux réduire le temps que prend le traitement des dossiers . [end]')\n",
      "('she can count from one to ten .', '[start] elle sait compter de un à dix . [end]')\n",
      "('i just have to do something .', \"[start] il me faut faire quelque chose , un point c'est tout . [end]\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "text_file = pathlib.Path(text_file).parent / \"fra.txt\"\n",
    "\n",
    "def normalize(line):\n",
    "    \"\"\"Normalize a line of text and split into two at the tab character\"\"\"\n",
    "    line = unicodedata.normalize(\"NFKC\", line.strip().lower())\n",
    "    line = re.sub(r\"^([^ \\w])(?!\\s)\", r\"\\1 \", line)\n",
    "    line = re.sub(r\"(\\s[^ \\w])(?!\\s)\", r\"\\1 \", line)\n",
    "    line = re.sub(r\"(?!\\s)([^ \\w])$\", r\" \\1\", line)\n",
    "    line = re.sub(r\"(?!\\s)([^ \\w]\\s)\", r\" \\1\", line)\n",
    "    eng, fra = line.split(\"\\t\")\n",
    "    fra = \"[start] \" + fra + \" [end]\"\n",
    "    return eng, fra\n",
    "\n",
    "# normalize each line and separate into English and French\n",
    "with open(text_file) as fp:\n",
    "    text_pairs = [normalize(line) for line in fp]\n",
    "\n",
    "# print some samples\n",
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))\n",
    "\n",
    "with open(\"text_pairs.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(text_pairs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
